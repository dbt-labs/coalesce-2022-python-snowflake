{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenges local development\n",
    "\n",
    "This notebook was used for locally developing Python code for the challenges. It also provides some visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yolo\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install --upgrade 'snowflake-snowpark-python[pandas]' pyyaml numpy pandas scikit-learn matplotlib seaborn prophet mlflow thefuzz ipympl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from thefuzz import fuzz\n",
    "from prophet import Prophet\n",
    "from datetime import datetime\n",
    "from sklearn.cluster import KMeans\n",
    "from prophet.serialize import model_to_json, model_from_json\n",
    "from snowflake.snowpark import Session\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from thefuzz.process import extractOne as match_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Snowpark in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace as needed\n",
    "PROFILE_PATH = \"/root/.dbt/profiles.yml\"\n",
    "PROFILE_NAME = \"snowflake\"\n",
    "PROFILE_OUTPUT = \"dev\"\n",
    "\n",
    "# read in dbt profile\n",
    "with open(PROFILE_PATH, \"r\") as f:\n",
    "    profiles = yaml.safe_load(f)\n",
    "    profile = profiles[PROFILE_NAME][\"outputs\"][PROFILE_OUTPUT]\n",
    "\n",
    "# build connection parameters from profile\n",
    "conn_params = {\n",
    "    \"account\": profile[\"account\"],\n",
    "    \"user\": profile[\"user\"],\n",
    "    \"role\": profile[\"role\"],\n",
    "    \"warehouse\": profile[\"warehouse\"],\n",
    "    \"database\": profile[\"database\"],\n",
    "    \"schema\": profile[\"schema\"],\n",
    "    \"authenticator\": profile[\"authenticator\"],\n",
    "}\n",
    "conn_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = conn_params[\"schema\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session\n",
    "\n",
    "s = Session.builder.configs(conn_params).create()\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.sql(\"select current_warehouse(), current_database(), current_schema()\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 1: describe the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = s.table(f\"{schema}.orders\").sample(frac=0.1).to_pandas()\n",
    "orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "described = orders.describe()\n",
    "described.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 2: pivot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_items = s.table(f\"{schema}.stg_order_items\").sample(frac=0.1).to_pandas()\n",
    "order_items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = s.table(f\"{schema}.stg_products\").to_pandas()\n",
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_ids = sorted(list(set(products[\"product_id\".upper()].unique())))\n",
    "product_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_item_product_subtotals = (\n",
    "    order_items.merge(products, on=\"product_id\".upper())\n",
    "    .groupby(\n",
    "        [\"order_id\".upper(), \"product_id\".upper()],\n",
    "        as_index=False,\n",
    "    )\n",
    "    .agg(SUBTOTAL=(\"product_price\".upper(), \"sum\"))\n",
    "    .reset_index()\n",
    "    .pivot(\n",
    "        index=\"order_id\".upper(),\n",
    "        columns=\"product_id\".upper(),\n",
    "        values=\"subtotal\".upper(),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "order_item_product_subtotals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renames = {product_id: f\"subtotal_{product_id}\".upper() for product_id in product_ids}\n",
    "order_item_product_subtotals = order_item_product_subtotals.rename(columns=renames)\n",
    "order_item_product_subtotals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_item_product_subtotals = order_item_product_subtotals.fillna(0)\n",
    "order_item_product_subtotals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_with_subtotals = orders.merge(\n",
    "    order_item_product_subtotals, on=\"order_id\".upper()\n",
    ")\n",
    "orders_with_subtotals.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 3: flag fuzzy duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = s.table(f\"{schema}.int_customers\").to_pandas()\n",
    "customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the earlier int_orders table that has the unmatch customer_names\n",
    "orders = s.table(f\"{schema}.int_orders\").sample(n=40).to_pandas()\n",
    "orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfuzzed = orders\n",
    "names = sorted(list(customers[\"customer_name\".upper()].unique()))\n",
    "unfuzzed[[\"matched_name\".upper(), \"matched_likelihood\".upper()]] = unfuzzed.apply(\n",
    "    lambda x: match_str(x[\"customer_name\".upper()], names),\n",
    "    axis=1,\n",
    "    result_type=\"expand\",\n",
    ")\n",
    "\n",
    "unfuzzed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 4: cluster customers by their order history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = orders_with_subtotals.select_dtypes(include=[\"number\"]).fillna(0).values\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detour: motivation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 3\n",
    "pca = PCA(n_components=n_components)\n",
    "pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = pca.fit(X)\n",
    "pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = pca.transform(X)\n",
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(projection=\"3d\")\n",
    "\n",
    "ax.scatter(\n",
    "    X_pca[:, 0],\n",
    "    X_pca[:, 1],\n",
    "    X_pca[:, 2],\n",
    "    c=orders_with_subtotals[\"subtotal\".upper()].values,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=5)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit(X)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = model.predict(X)\n",
    "cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(projection=\"3d\")\n",
    "\n",
    "ax.scatter(\n",
    "    X_pca[:, 0],\n",
    "    X_pca[:, 1],\n",
    "    X_pca[:, 2],\n",
    "    c=cluster_labels,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(data=cluster_labels, columns=[\"cluster_label\"])\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_with_subtotals_and_clusters = orders_with_subtotals.merge(\n",
    "    temp, left_index=True, right_index=True\n",
    ")\n",
    "orders_with_subtotals_and_clusters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 5: predict revenue by location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue = s.table(f\"{schema}.revenue_weekly_by_location\").to_pandas()\n",
    "revenue.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renames = {\n",
    "    \"date_week\".upper(): \"ds\",\n",
    "    \"location_name\".upper(): \"location\",\n",
    "    \"revenue\".upper(): \"y\",\n",
    "}\n",
    "revenue = revenue.rename(columns=renames)\n",
    "revenue.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = sorted(list(revenue[\"location\"].unique()))\n",
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    location: Prophet().fit(revenue[revenue[\"location\"] == location])\n",
    "    for location in locations\n",
    "}\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = models[locations[0]].make_future_dataframe(periods=52 * 3, freq=\"W\")\n",
    "future.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts = {location: models[location].predict(future) for location in locations}\n",
    "forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for location in locations:\n",
    "    models[location].plot(forecasts[location])\n",
    "    plt.title(location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using the dbt models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = s.table(f\"{schema}.forecast_train_py\").to_pandas()\n",
    "models.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = sorted(list(models[\"location\"].unique()))\n",
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_recent_trained_at = models[\"trained_at\"].max()\n",
    "most_recent_trained_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = models[models[\"trained_at\"] == most_recent_trained_at]\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    location: model_from_json(models[models[\"location\"] == location][\"model\"].iloc[0])\n",
    "    for location in locations\n",
    "}\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts = s.table(f\"{schema}.forecast_score_py\").to_pandas()\n",
    "forecasts.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hack -- datetime in Snowpark/Pandas funkiness\n",
    "forecasts[\"ds\"] /= 1e6\n",
    "forecasts[\"ds\"] = pd.to_datetime(forecasts[\"ds\"], unit=\"s\")\n",
    "forecasts.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for location in locations:\n",
    "    models[location].plot(forecasts[forecasts[\"location\"] == location])\n",
    "    plt.title(location)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowy",
   "language": "python",
   "name": "snowy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ac17d4cedbba552a600d528720f89ee3cc4ded352c6e87200df10223fc1669a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
