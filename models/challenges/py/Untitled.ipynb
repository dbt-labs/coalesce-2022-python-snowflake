{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenges local development\n",
    "\n",
    "This notebook was used for locally developing Python code for the challenges. It also provides some visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yolo\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install --upgrade 'snowflake-snowpark-python[pandas]' pyyaml numpy pandas scikit-learn matplotlib seaborn prophet mlflow thefuzz ipympl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from random import random, randint\n",
    "from thefuzz import fuzz\n",
    "from prophet import Prophet\n",
    "from datetime import datetime\n",
    "from sklearn.cluster import KMeans\n",
    "from prophet.serialize import model_to_json, model_from_json\n",
    "from snowflake.snowpark import Session\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from thefuzz.process import extractOne as match_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Snowpark in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace as needed\n",
    "PROFILE_PATH = \"/root/.dbt/profiles.yml\"\n",
    "PROFILE_NAME = \"snowflake\"\n",
    "PROFILE_OUTPUT = \"dev\"\n",
    "\n",
    "# read in dbt profile\n",
    "with open(PROFILE_PATH, \"r\") as f:\n",
    "    profiles = yaml.safe_load(f)\n",
    "    profile = profiles[PROFILE_NAME][\"outputs\"][PROFILE_OUTPUT]\n",
    "\n",
    "# build connection parameters from profile\n",
    "conn_params = {\n",
    "    \"account\": profile[\"account\"],\n",
    "    \"user\": profile[\"user\"],\n",
    "    \"role\": profile[\"role\"],\n",
    "    \"warehouse\": profile[\"warehouse\"],\n",
    "    \"database\": profile[\"database\"],\n",
    "    \"schema\": profile[\"schema\"],\n",
    "    \"authenticator\": profile[\"authenticator\"],\n",
    "}\n",
    "conn_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = conn_params[\"schema\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session\n",
    "\n",
    "s = Session.builder.configs(conn_params).create()\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.sql(\"select current_warehouse(), current_database(), current_schema()\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 1: describe the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = s.table(f\"{schema}.orders\")\n",
    "orders.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "described = orders.describe()\n",
    "described.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 2: pivot the data\n",
    "\n",
    "Resorting to Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = s.table(f\"{schema}.orders\").sample(frac=0.2).to_pandas()\n",
    "orders.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_items = s.table(f\"{schema}.stg_order_items\").sample(frac=0.2).to_pandas()\n",
    "order_items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = s.table(f\"{schema}.stg_products\").to_pandas()\n",
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_ids = sorted(list(set(products[\"product_id\".upper()].unique())))\n",
    "product_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_item_product_subtotals = (\n",
    "    order_items.merge(products, on=\"product_id\".upper())\n",
    "    .groupby(\n",
    "        [\"order_id\".upper(), \"product_id\".upper()],\n",
    "        as_index=False,\n",
    "    )\n",
    "    .agg(SUBTOTAL=(\"product_price\".upper(), \"sum\"))\n",
    "    .reset_index()\n",
    "    .pivot(\n",
    "        index=\"order_id\".upper(),\n",
    "        columns=\"product_id\".upper(),\n",
    "        values=\"subtotal\".upper(),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "order_item_product_subtotals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renames = {product_id: f\"subtotal_{product_id}\".upper() for product_id in product_ids}\n",
    "order_item_product_subtotals = order_item_product_subtotals.rename(columns=renames)\n",
    "order_item_product_subtotals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_item_product_subtotals = order_item_product_subtotals.fillna(0)\n",
    "order_item_product_subtotals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_with_subtotals = orders.merge(\n",
    "    order_item_product_subtotals, on=\"order_id\".upper()\n",
    ")\n",
    "orders_with_subtotals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 3: flag fuzzy duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = s.table(f\"{schema}.customers\").to_pandas()\n",
    "customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\"customer_id\", \"customer_order_index\", \"is_first_order\"]\n",
    "drop_cols.extend([col for col in customers.columns if col != \"customer_name\".upper()])\n",
    "drop_cols = [col.upper() for col in drop_cols]\n",
    "\n",
    "fuzzed = orders.merge(customers, on=\"customer_id\".upper()).drop(drop_cols, axis=1)\n",
    "fuzzed.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = fuzzed[\"customer_name\".upper()]\n",
    "names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzz_name(name):\n",
    "\n",
    "    fuzz_name = \"\"\n",
    "    names = name.split(\" \")\n",
    "\n",
    "    for name in names:\n",
    "        if random() < 0.5:\n",
    "            # employee or AI is decisive\n",
    "            if random() < 0.5:\n",
    "                # and loves all caps\n",
    "                name = name.upper()\n",
    "            else:\n",
    "                # or all lowercase\n",
    "                name = name.lower()\n",
    "\n",
    "        if random() < 0.2:\n",
    "            # AI dropped the first or last letter probably :/\n",
    "            if random() < 0.5:\n",
    "                # first letter dropped, whoops\n",
    "                name = name[1:]\n",
    "            else:\n",
    "                # last letter dropped, whoops\n",
    "                name = name[:-1]\n",
    "\n",
    "        if random() < 0.1:\n",
    "            # a solar flare hit the datacenter in all regions,\n",
    "            # no multi-region resiliency could have saved it :(\n",
    "            for char in name:\n",
    "                if random() < 0.3:\n",
    "                    name = name.replace(char, chr(ord(char) + randint(-5, 5)))\n",
    "\n",
    "        fuzz_name += name + \" \"\n",
    "\n",
    "    return fuzz_name.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzed_names = [fuzz_name(name) for name in names]\n",
    "fuzzed_names[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzed[\"customer_name\".upper()] = fuzzed_names\n",
    "fuzzed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_names = sorted(list(set(customers[\"customer_name\".upper()].unique())))\n",
    "customer_names[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes a very long time to run\n",
    "if False:\n",
    "    unfuzzed = fuzzed\n",
    "    unfuzzed[\"customer_name_unfuzeed\".upper()] = fuzzed[\"customer_name\".upper()].apply(\n",
    "        lambda x: match_str(x, customer_names)[0]\n",
    "    )\n",
    "    unfuzzed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 4: cluster customers by their order history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = orders_with_subtotals\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.select_dtypes(include=[\"number\"]).values\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detour: motivation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 3\n",
    "pca = PCA(n_components=n_components)\n",
    "pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = pca.fit(X)\n",
    "pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = pca.transform(X)\n",
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(projection=\"3d\")\n",
    "\n",
    "ax.scatter(\n",
    "    X_pca[:, 0],\n",
    "    X_pca[:, 1],\n",
    "    X_pca[:, 2],\n",
    "    c=df[\"subtotal\".upper()].values,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=5)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit(X)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = model.predict(X)\n",
    "cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(projection=\"3d\")\n",
    "\n",
    "ax.scatter(\n",
    "    X_pca[:, 0],\n",
    "    X_pca[:, 1],\n",
    "    X_pca[:, 2],\n",
    "    c=cluster_labels,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(data=cluster_labels, columns=[\"cluster_label\"])\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_with_subtotals_and_clusters = orders_with_subtotals.merge(\n",
    "    temp, left_index=True, right_index=True\n",
    ")\n",
    "orders_with_subtotals_and_clusters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 5: predict revenue by location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue = s.table(f\"{schema}.revenue_weekly_by_location\").to_pandas()\n",
    "revenue.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renames = {\n",
    "    \"date_week\".upper(): \"ds\",\n",
    "    \"location_name\".upper(): \"location\",\n",
    "    \"revenue\".upper(): \"y\",\n",
    "}\n",
    "revenue = revenue.rename(columns=renames)\n",
    "revenue.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = sorted(list(revenue[\"location\"].unique()))\n",
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    location: Prophet().fit(revenue[revenue[\"location\"] == location])\n",
    "    for location in locations\n",
    "}\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = models[locations[0]].make_future_dataframe(periods=52 * 3, freq=\"W\")\n",
    "future.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts = {location: models[location].predict(future) for location in locations}\n",
    "forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for location in locations:\n",
    "    models[location].plot(forecasts[location])\n",
    "    plt.title(location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using the dbt models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = s.table(f\"{schema}.forecast_train_py\").to_pandas()\n",
    "models.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = sorted(list(models[\"location\"].unique()))\n",
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_recent_trained_at = models[\"trained_at\"].max()\n",
    "most_recent_trained_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = models[models[\"trained_at\"] == most_recent_trained_at]\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    location: model_from_json(models[models[\"location\"] == location][\"model\"].iloc[0])\n",
    "    for location in locations\n",
    "}\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts = s.table(f\"{schema}.forecast_score_py\").to_pandas()\n",
    "forecasts.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hack -- datetime in Snowpark/Pandas funkiness\n",
    "forecasts[\"ds\"] /= 1e6\n",
    "forecasts[\"ds\"] = pd.to_datetime(forecasts[\"ds\"], unit=\"s\")\n",
    "forecasts.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for location in locations:\n",
    "    models[location].plot(forecasts[forecasts[\"location\"] == location])\n",
    "    plt.title(location)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowy",
   "language": "python",
   "name": "snowy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
